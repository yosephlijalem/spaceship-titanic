{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12abf851-2716-4e04-bdf5-e0c8b270297a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (8693, 14) | test shape: (4277, 14)\n",
      "n_features: 14 | n_categorical: 6\n",
      "first 3 feature columns: ['HomePlanet', 'CryoSleep', 'Destination']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>CabinDeck</th>\n",
       "      <th>CabinNum</th>\n",
       "      <th>CabinSide</th>\n",
       "      <th>TotalSpend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>P</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "      <td>736.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S</td>\n",
       "      <td>10383.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  HomePlanet CryoSleep  Destination   Age    VIP  RoomService  FoodCourt  \\\n",
       "0     Europa     False  TRAPPIST-1e  39.0  False          0.0        0.0   \n",
       "1      Earth     False  TRAPPIST-1e  24.0  False        109.0        9.0   \n",
       "2     Europa     False  TRAPPIST-1e  58.0   True         43.0     3576.0   \n",
       "\n",
       "   ShoppingMall     Spa  VRDeck CabinDeck  CabinNum CabinSide  TotalSpend  \n",
       "0           0.0     0.0     0.0         B       0.0         P         0.0  \n",
       "1          25.0   549.0    44.0         F       0.0         S       736.0  \n",
       "2           0.0  6715.0    49.0         A       0.0         S     10383.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "\n",
    "# Load data\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test  = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# ----- Feature prep helpers -----\n",
    "def _split_cabin(x):\n",
    "    if pd.isna(x):\n",
    "        return pd.Series({\"CabinDeck\": np.nan, \"CabinNum\": np.nan, \"CabinSide\": np.nan})\n",
    "    parts = str(x).split(\"/\")\n",
    "    deck = parts[0] if len(parts) > 0 else np.nan\n",
    "    num  = pd.to_numeric(parts[1], errors=\"coerce\") if len(parts) > 1 else np.nan\n",
    "    side = parts[2] if len(parts) > 2 else np.nan\n",
    "    return pd.Series({\"CabinDeck\": deck, \"CabinNum\": num, \"CabinSide\": side})\n",
    "\n",
    "def prepare(df):\n",
    "    df = df.copy()\n",
    "    # Cabin parsed\n",
    "    df = pd.concat([df, df[\"Cabin\"].apply(_split_cabin)], axis=1)\n",
    "    # Total spend\n",
    "    spend_cols = [\"RoomService\",\"FoodCourt\",\"ShoppingMall\",\"Spa\",\"VRDeck\"]\n",
    "    df[\"TotalSpend\"] = df[spend_cols].sum(axis=1, min_count=1)\n",
    "    # Columns\n",
    "    drop_cols = [\"PassengerId\",\"Name\",\"Cabin\",\"Transported\"]\n",
    "    feat_cols = [c for c in df.columns if c not in drop_cols]\n",
    "    cat_cols  = [c for c in feat_cols if df[c].dtype == \"object\" or df[c].dtype == bool]\n",
    "    return df, feat_cols, cat_cols\n",
    "\n",
    "# Prep\n",
    "train_prep, feat_cols, cat_cols = prepare(train)\n",
    "test_prep,  _,        _        = prepare(test)\n",
    "\n",
    "X = train_prep[feat_cols]\n",
    "y = train[\"Transported\"].astype(int)\n",
    "\n",
    "cat_idx = [X.columns.get_loc(c) for c in cat_cols]\n",
    "\n",
    "print(\"X shape:\", X.shape, \"| test shape:\", test_prep[feat_cols].shape)\n",
    "print(\"n_features:\", len(feat_cols), \"| n_categorical:\", len(cat_cols))\n",
    "print(\"first 3 feature columns:\", feat_cols[:3])\n",
    "X.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc36c3e5-12e6-452d-b416-5172ff757d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.7773943\ttest: 0.7734330\tbest: 0.7734330 (0)\ttotal: 263ms\tremaining: 8m 46s\n",
      "100:\tlearn: 0.8402358\ttest: 0.8251869\tbest: 0.8251869 (100)\ttotal: 13.3s\tremaining: 4m 10s\n",
      "200:\tlearn: 0.8845269\ttest: 0.8211616\tbest: 0.8257619 (102)\ttotal: 26.7s\tremaining: 3m 58s\n",
      "300:\tlearn: 0.9105551\ttest: 0.8228867\tbest: 0.8257619 (102)\ttotal: 40.2s\tremaining: 3m 47s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.8257619321\n",
      "bestIteration = 102\n",
      "\n",
      "Shrink model to first 103 iterations.\n",
      "Fold 1: acc=0.82576, best_iter=102\n",
      "0:\tlearn: 0.7824274\ttest: 0.7659574\tbest: 0.7659574 (0)\ttotal: 123ms\tremaining: 4m 5s\n",
      "100:\tlearn: 0.8457003\ttest: 0.8056354\tbest: 0.8085106 (90)\ttotal: 12.7s\tremaining: 3m 59s\n",
      "200:\tlearn: 0.8805004\ttest: 0.8050604\tbest: 0.8096607 (143)\ttotal: 25.7s\tremaining: 3m 49s\n",
      "300:\tlearn: 0.9020708\ttest: 0.8050604\tbest: 0.8096607 (143)\ttotal: 39.6s\tremaining: 3m 43s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.8096607246\n",
      "bestIteration = 143\n",
      "\n",
      "Shrink model to first 144 iterations.\n",
      "Fold 2: acc=0.80966, best_iter=143\n",
      "0:\tlearn: 0.7717860\ttest: 0.7728580\tbest: 0.7728580 (0)\ttotal: 119ms\tremaining: 3m 58s\n",
      "100:\tlearn: 0.8469945\ttest: 0.8194365\tbest: 0.8217366 (99)\ttotal: 13.1s\tremaining: 4m 6s\n",
      "200:\tlearn: 0.8937302\ttest: 0.8159862\tbest: 0.8228867 (145)\ttotal: 26.2s\tremaining: 3m 54s\n",
      "300:\tlearn: 0.9187518\ttest: 0.8165612\tbest: 0.8228867 (145)\ttotal: 39.4s\tremaining: 3m 42s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.8228867165\n",
      "bestIteration = 145\n",
      "\n",
      "Shrink model to first 146 iterations.\n",
      "Fold 3: acc=0.82289, best_iter=145\n",
      "0:\tlearn: 0.7742631\ttest: 0.7681243\tbest: 0.7681243 (0)\ttotal: 118ms\tremaining: 3m 56s\n",
      "100:\tlearn: 0.8425593\ttest: 0.8164557\tbest: 0.8176064 (82)\ttotal: 12.2s\tremaining: 3m 50s\n",
      "200:\tlearn: 0.8855500\ttest: 0.8204833\tbest: 0.8210587 (195)\ttotal: 25.5s\tremaining: 3m 48s\n",
      "300:\tlearn: 0.9124371\ttest: 0.8181818\tbest: 0.8216341 (203)\ttotal: 38.8s\tremaining: 3m 39s\n",
      "400:\tlearn: 0.9350108\ttest: 0.8164557\tbest: 0.8233602 (348)\ttotal: 52.4s\tremaining: 3m 28s\n",
      "500:\tlearn: 0.9488138\ttest: 0.8170311\tbest: 0.8233602 (348)\ttotal: 1m 6s\tremaining: 3m 18s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.8233601841\n",
      "bestIteration = 348\n",
      "\n",
      "Shrink model to first 349 iterations.\n",
      "Fold 4: acc=0.82336, best_iter=348\n",
      "0:\tlearn: 0.7649173\ttest: 0.7543153\tbest: 0.7543153 (0)\ttotal: 120ms\tremaining: 3m 59s\n",
      "100:\tlearn: 0.8455787\ttest: 0.7968930\tbest: 0.8014960 (89)\ttotal: 12.7s\tremaining: 3m 58s\n",
      "200:\tlearn: 0.8901510\ttest: 0.8009206\tbest: 0.8026467 (189)\ttotal: 26s\tremaining: 3m 52s\n",
      "300:\tlearn: 0.9095615\ttest: 0.7997699\tbest: 0.8026467 (189)\ttotal: 39.4s\tremaining: 3m 42s\n",
      "400:\tlearn: 0.9319914\ttest: 0.7997699\tbest: 0.8049482 (373)\ttotal: 53.1s\tremaining: 3m 31s\n",
      "500:\tlearn: 0.9478073\ttest: 0.7957422\tbest: 0.8049482 (373)\ttotal: 1m 6s\tremaining: 3m 18s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.8049482163\n",
      "bestIteration = 373\n",
      "\n",
      "Shrink model to first 374 iterations.\n",
      "Fold 5: acc=0.80495, best_iter=373\n",
      "\n",
      "CV Accuracy: mean=0.81732, std=0.00837\n",
      "Best iters per fold: [102, 143, 145, 348, 373]\n"
     ]
    }
   ],
   "source": [
    "# 5-fold Stratified CV with CatBoost\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from catboost import CatBoostClassifier\n",
    "import numpy as np\n",
    "\n",
    "# CatBoost needs categorical NaNs converted to strings\n",
    "X_cv = X.copy()\n",
    "for c in cat_cols:\n",
    "    X_cv[c] = X_cv[c].astype(\"object\").fillna(\"Missing\").astype(str)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accs, best_ns = [], []\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(skf.split(X_cv, y), 1):\n",
    "    X_tr, X_va = X_cv.iloc[tr_idx], X_cv.iloc[va_idx]\n",
    "    y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "\n",
    "    cat_idx = [X_tr.columns.get_loc(c) for c in cat_cols]\n",
    "\n",
    "    model = CatBoostClassifier(\n",
    "        loss_function=\"Logloss\",\n",
    "        eval_metric=\"Accuracy\",\n",
    "        depth=8,\n",
    "        learning_rate=0.08,\n",
    "        n_estimators=2000,\n",
    "        l2_leaf_reg=3,\n",
    "        random_seed=42,\n",
    "        verbose=100\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_tr, y_tr,\n",
    "        cat_features=cat_idx,\n",
    "        eval_set=(X_va, y_va),\n",
    "        use_best_model=True,\n",
    "        early_stopping_rounds=200\n",
    "    )\n",
    "\n",
    "    pred_va = model.predict(X_va)\n",
    "    acc = accuracy_score(y_va, pred_va)\n",
    "    accs.append(acc)\n",
    "    best_ns.append(model.get_best_iteration() or model.tree_count_)\n",
    "    print(f\"Fold {fold}: acc={acc:.5f}, best_iter={best_ns[-1]}\")\n",
    "\n",
    "print(\"\\nCV Accuracy: mean={:.5f}, std={:.5f}\".format(np.mean(accs), np.std(accs)))\n",
    "print(\"Best iters per fold:\", best_ns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c844a7a-b92a-49a2-9c80-f03ed7874a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using n_estimators: 145\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId  Transported\n",
       "0     0013_01         True\n",
       "1     0018_01        False\n",
       "2     0019_01         True\n",
       "3     0021_01         True\n",
       "4     0023_01        False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Refit on ALL data using CV-informed n_estimators (median of best per fold)\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier\n",
    "import pandas as pd\n",
    "\n",
    "best_n = int(np.median(best_ns))  # best_ns came from the CV cell\n",
    "print(\"Using n_estimators:\", best_n)\n",
    "\n",
    "# Build full matrices\n",
    "X_all  = train_prep[feat_cols].copy()\n",
    "X_test = test_prep[feat_cols].copy()\n",
    "\n",
    "# Sanitize categoricals for CatBoost\n",
    "for c in cat_cols:\n",
    "    X_all[c]  = X_all[c].astype(\"object\").fillna(\"Missing\").astype(str)\n",
    "    X_test[c] = X_test[c].astype(\"object\").fillna(\"Missing\").astype(str)\n",
    "\n",
    "cat_idx_all = [X_all.columns.get_loc(c) for c in cat_cols]\n",
    "\n",
    "model_full_cv = CatBoostClassifier(\n",
    "    loss_function=\"Logloss\",\n",
    "    eval_metric=\"Accuracy\",\n",
    "    depth=8,\n",
    "    learning_rate=0.08,\n",
    "    n_estimators=best_n,\n",
    "    l2_leaf_reg=3,\n",
    "    random_seed=42,\n",
    "    verbose=False\n",
    ")\n",
    "model_full_cv.fit(X_all, y, cat_features=cat_idx_all)\n",
    "\n",
    "proba = model_full_cv.predict_proba(X_test)[:, 1]\n",
    "pred_bool = proba >= 0.5\n",
    "\n",
    "sub_cv = pd.DataFrame({\n",
    "    \"PassengerId\": test[\"PassengerId\"],\n",
    "    \"Transported\": pred_bool\n",
    "})\n",
    "sub_cv.to_csv(\"submission_catboost_cv.csv\", index=False)\n",
    "sub_cv.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e9ee2b1-7ae4-4f90-82a6-5fb5a398f291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (8693, 17) | test shape: (4277, 17)\n",
      "now including: ['GroupID', 'GroupSize', 'IsAlone']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GroupID</th>\n",
       "      <th>GroupSize</th>\n",
       "      <th>IsAlone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  GroupID  GroupSize  IsAlone\n",
       "0    0001          1     True\n",
       "1    0002          1     True\n",
       "2    0003          2    False\n",
       "3    0003          2    False\n",
       "4    0004          1     True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build group features from PassengerId and rebuild matrices\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# counts across train+test (safe: uses IDs only, no target)\n",
    "all_ids = pd.concat([train[\"PassengerId\"], test[\"PassengerId\"]], ignore_index=True)\n",
    "gid_counts = all_ids.str.split(\"_\", n=1, expand=True)[0].value_counts()\n",
    "\n",
    "def prepare2(df):\n",
    "    df = df.copy()\n",
    "    # Cabin parsed\n",
    "    df = pd.concat([df, df[\"Cabin\"].apply(_split_cabin)], axis=1)\n",
    "    # Total spend\n",
    "    spend_cols = [\"RoomService\",\"FoodCourt\",\"ShoppingMall\",\"Spa\",\"VRDeck\"]\n",
    "    df[\"TotalSpend\"] = df[spend_cols].sum(axis=1, min_count=1)\n",
    "    # Group features\n",
    "    gid = df[\"PassengerId\"].str.split(\"_\", n=1, expand=True)[0]\n",
    "    df[\"GroupID\"] = gid\n",
    "    df[\"GroupSize\"] = gid.map(gid_counts).astype(\"Int64\")\n",
    "    df[\"IsAlone\"] = (df[\"GroupSize\"].fillna(1) == 1)\n",
    "    # Feature lists\n",
    "    drop_cols = [\"PassengerId\",\"Name\",\"Cabin\",\"Transported\"]\n",
    "    feat_cols = [c for c in df.columns if c not in drop_cols]\n",
    "    cat_cols  = [c for c in feat_cols if df[c].dtype == \"object\" or df[c].dtype == bool]\n",
    "    return df, feat_cols, cat_cols\n",
    "\n",
    "# rebuild with new features\n",
    "train_prep, feat_cols, cat_cols = prepare2(train)\n",
    "test_prep,  _,        _        = prepare2(test)\n",
    "X = train_prep[feat_cols]\n",
    "y = train[\"Transported\"].astype(int)\n",
    "\n",
    "print(\"X shape:\", X.shape, \"| test shape:\", test_prep[feat_cols].shape)\n",
    "print(\"now including:\", [c for c in [\"GroupID\",\"GroupSize\",\"IsAlone\"] if c in feat_cols])\n",
    "X[[\"GroupID\",\"GroupSize\",\"IsAlone\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb9d9438-f545-4649-b173-52753c7ea502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.7342537\ttest: 0.7441058\tbest: 0.7441058 (0)\ttotal: 42.6ms\tremaining: 1m 25s\n",
      "100:\tlearn: 0.8455565\ttest: 0.8234618\tbest: 0.8234618 (94)\ttotal: 13.9s\tremaining: 4m 21s\n",
      "200:\tlearn: 0.8901352\ttest: 0.8177113\tbest: 0.8234618 (94)\ttotal: 28.1s\tremaining: 4m 11s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.8234617596\n",
      "bestIteration = 94\n",
      "\n",
      "Shrink model to first 95 iterations.\n",
      "Fold 1: acc=0.82346, best_iter=94\n",
      "0:\tlearn: 0.7496405\ttest: 0.7360552\tbest: 0.7360552 (0)\ttotal: 128ms\tremaining: 4m 16s\n",
      "100:\tlearn: 0.8498706\ttest: 0.8050604\tbest: 0.8050604 (97)\ttotal: 13.7s\tremaining: 4m 16s\n",
      "200:\tlearn: 0.8861087\ttest: 0.8079356\tbest: 0.8119609 (172)\ttotal: 27.8s\tremaining: 4m 9s\n",
      "300:\tlearn: 0.9114179\ttest: 0.8073606\tbest: 0.8119609 (172)\ttotal: 41.8s\tremaining: 3m 55s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.8119608971\n",
      "bestIteration = 172\n",
      "\n",
      "Shrink model to first 173 iterations.\n",
      "Fold 2: acc=0.81196, best_iter=172\n",
      "0:\tlearn: 0.7660339\ttest: 0.7625072\tbest: 0.7625072 (0)\ttotal: 142ms\tremaining: 4m 44s\n",
      "100:\tlearn: 0.8469945\ttest: 0.8154112\tbest: 0.8154112 (100)\ttotal: 14.6s\tremaining: 4m 34s\n",
      "200:\tlearn: 0.8885534\ttest: 0.8136860\tbest: 0.8154112 (100)\ttotal: 29s\tremaining: 4m 19s\n",
      "300:\tlearn: 0.9145815\ttest: 0.8159862\tbest: 0.8159862 (201)\ttotal: 43.3s\tremaining: 4m 4s\n",
      "400:\tlearn: 0.9370147\ttest: 0.8142611\tbest: 0.8159862 (201)\ttotal: 57.5s\tremaining: 3m 49s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.815986199\n",
      "bestIteration = 201\n",
      "\n",
      "Shrink model to first 202 iterations.\n",
      "Fold 3: acc=0.81599, best_iter=201\n",
      "0:\tlearn: 0.7732566\ttest: 0.7612198\tbest: 0.7612198 (0)\ttotal: 136ms\tremaining: 4m 32s\n",
      "100:\tlearn: 0.8491733\ttest: 0.8193326\tbest: 0.8210587 (81)\ttotal: 13.4s\tremaining: 4m 12s\n",
      "200:\tlearn: 0.8871316\ttest: 0.8158803\tbest: 0.8227848 (122)\ttotal: 27.4s\tremaining: 4m 5s\n",
      "300:\tlearn: 0.9141625\ttest: 0.8222094\tbest: 0.8239356 (255)\ttotal: 41.4s\tremaining: 3m 53s\n",
      "400:\tlearn: 0.9364486\ttest: 0.8199079\tbest: 0.8239356 (255)\ttotal: 55.6s\tremaining: 3m 41s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.8239355581\n",
      "bestIteration = 255\n",
      "\n",
      "Shrink model to first 256 iterations.\n",
      "Fold 4: acc=0.82394, best_iter=255\n",
      "0:\tlearn: 0.7468009\ttest: 0.7387802\tbest: 0.7387802 (0)\ttotal: 126ms\tremaining: 4m 11s\n",
      "100:\tlearn: 0.8454349\ttest: 0.7980437\tbest: 0.7980437 (97)\ttotal: 13.7s\tremaining: 4m 17s\n",
      "200:\tlearn: 0.8881380\ttest: 0.8066743\tbest: 0.8089758 (161)\ttotal: 27.9s\tremaining: 4m 9s\n",
      "300:\tlearn: 0.9164630\ttest: 0.8055236\tbest: 0.8130035 (255)\ttotal: 42.1s\tremaining: 3m 57s\n",
      "400:\tlearn: 0.9331416\ttest: 0.8032221\tbest: 0.8130035 (255)\ttotal: 56.1s\tremaining: 3m 43s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.8130034522\n",
      "bestIteration = 255\n",
      "\n",
      "Shrink model to first 256 iterations.\n",
      "Fold 5: acc=0.81300, best_iter=255\n",
      "\n",
      "CV Accuracy: mean=0.81767, std=0.00510\n",
      "Best iters per fold: [94, 172, 201, 255, 255]\n"
     ]
    }
   ],
   "source": [
    "# 5-fold CV with GroupID/GroupSize/IsAlone included\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from catboost import CatBoostClassifier\n",
    "import numpy as np\n",
    "\n",
    "X_cv = X.copy()\n",
    "for c in cat_cols:\n",
    "    X_cv[c] = X_cv[c].astype(\"object\").fillna(\"Missing\").astype(str)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accs, best_ns = [], []\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(skf.split(X_cv, y), 1):\n",
    "    X_tr, X_va = X_cv.iloc[tr_idx], X_cv.iloc[va_idx]\n",
    "    y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "    cat_idx = [X_tr.columns.get_loc(c) for c in cat_cols]\n",
    "\n",
    "    model = CatBoostClassifier(\n",
    "        loss_function=\"Logloss\",\n",
    "        eval_metric=\"Accuracy\",\n",
    "        depth=8,\n",
    "        learning_rate=0.08,\n",
    "        n_estimators=2000,\n",
    "        l2_leaf_reg=3,\n",
    "        random_seed=42,\n",
    "        verbose=100\n",
    "    )\n",
    "    model.fit(\n",
    "        X_tr, y_tr,\n",
    "        cat_features=cat_idx,\n",
    "        eval_set=(X_va, y_va),\n",
    "        use_best_model=True,\n",
    "        early_stopping_rounds=200\n",
    "    )\n",
    "\n",
    "    pred_va = model.predict(X_va)\n",
    "    accs.append(accuracy_score(y_va, pred_va))\n",
    "    best_ns.append(model.get_best_iteration() or model.tree_count_)\n",
    "    print(f\"Fold {fold}: acc={accs[-1]:.5f}, best_iter={best_ns[-1]}\")\n",
    "\n",
    "print(\"\\nCV Accuracy: mean={:.5f}, std={:.5f}\".format(np.mean(accs), np.std(accs)))\n",
    "print(\"Best iters per fold:\", best_ns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fff3afb2-91a0-4153-8a1a-23e0342c8716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using n_estimators: 201\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId  Transported\n",
       "0     0013_01         True\n",
       "1     0018_01        False\n",
       "2     0019_01         True\n",
       "3     0021_01         True\n",
       "4     0023_01         True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Refit using median best iteration from CV and export submission\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "best_n = int(np.median(best_ns))  # e.g., from [94,172,201,255,255] -> 201\n",
    "print(\"Using n_estimators:\", best_n)\n",
    "\n",
    "X_all  = train_prep[feat_cols].copy()\n",
    "X_test = test_prep[feat_cols].copy()\n",
    "\n",
    "for c in cat_cols:\n",
    "    X_all[c]  = X_all[c].astype(\"object\").fillna(\"Missing\").astype(str)\n",
    "    X_test[c] = X_test[c].astype(\"object\").fillna(\"Missing\").astype(str)\n",
    "\n",
    "cat_idx_all = [X_all.columns.get_loc(c) for c in cat_cols]\n",
    "\n",
    "model_full_groups = CatBoostClassifier(\n",
    "    loss_function=\"Logloss\",\n",
    "    eval_metric=\"Accuracy\",\n",
    "    depth=8,\n",
    "    learning_rate=0.08,\n",
    "    n_estimators=best_n,\n",
    "    l2_leaf_reg=3,\n",
    "    random_seed=42,\n",
    "    verbose=False\n",
    ")\n",
    "model_full_groups.fit(X_all, y, cat_features=cat_idx_all)\n",
    "\n",
    "proba = model_full_groups.predict_proba(X_test)[:, 1]\n",
    "pred_bool = proba >= 0.5\n",
    "\n",
    "sub_groups = pd.DataFrame({\n",
    "    \"PassengerId\": test[\"PassengerId\"],\n",
    "    \"Transported\": pred_bool\n",
    "})\n",
    "sub_groups.to_csv(\"submission_catboost_groups_cv.csv\", index=False)\n",
    "sub_groups.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "495669a1-bb3f-45e1-ba13-77da6be6d748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.500\n",
      "CV acc at best_t: 0.81353\n",
      "CV acc at 0.500: 0.81353\n"
     ]
    }
   ],
   "source": [
    "# Find best probability threshold via 5-fold CV (uses best_ns from last CV)\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# 1) Build CV matrices with sanitized categoricals\n",
    "X_cv = X.copy()\n",
    "for c in cat_cols:\n",
    "    X_cv[c] = X_cv[c].astype(\"object\").fillna(\"Missing\").astype(str)\n",
    "\n",
    "probas_val = np.zeros(len(X))\n",
    "y_true = y.values.copy()\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for i, (tr_idx, va_idx) in enumerate(skf.split(X_cv, y), 0):\n",
    "    X_tr, X_va = X_cv.iloc[tr_idx], X_cv.iloc[va_idx]\n",
    "    y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "    cat_idx = [X_tr.columns.get_loc(c) for c in cat_cols]\n",
    "    n_estimators = best_ns[i] if 'best_ns' in globals() and len(best_ns)==5 else 200\n",
    "\n",
    "    m = CatBoostClassifier(\n",
    "        loss_function=\"Logloss\",\n",
    "        eval_metric=\"Accuracy\",\n",
    "        depth=8,\n",
    "        learning_rate=0.08,\n",
    "        n_estimators=n_estimators,\n",
    "        l2_leaf_reg=3,\n",
    "        random_seed=42,\n",
    "        verbose=False\n",
    "    )\n",
    "    m.fit(X_tr, y_tr, cat_features=cat_idx)\n",
    "    probas_val[va_idx] = m.predict_proba(X_va)[:, 1]\n",
    "\n",
    "# 2) Grid search threshold for max accuracy\n",
    "grid = np.linspace(0.35, 0.65, 61)  # 0.35..0.65 step 0.005\n",
    "acc_05 = accuracy_score(y_true, (probas_val >= 0.5).astype(int))\n",
    "best_t, best_acc = 0.5, acc_05\n",
    "for t in grid:\n",
    "    acc = accuracy_score(y_true, (probas_val >= t).astype(int))\n",
    "    if acc > best_acc:\n",
    "        best_t, best_acc = float(t), acc\n",
    "\n",
    "print(f\"Best threshold: {best_t:.3f}\")\n",
    "print(f\"CV acc at best_t: {best_acc:.5f}\")\n",
    "print(f\"CV acc at 0.500: {acc_05:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "304d8896-3e13-4117-b057-a1ed3389fb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (8693, 20) | test shape: (4277, 20)\n",
      "new features present: ['LogTotalSpend', 'AnySpend', 'AgeBin']\n"
     ]
    }
   ],
   "source": [
    "# Add AgeBin, LogTotalSpend, AnySpend and rebuild features\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def prepare3(df):\n",
    "    df = df.copy()\n",
    "    # Cabin parsed\n",
    "    df = pd.concat([df, df[\"Cabin\"].apply(_split_cabin)], axis=1)\n",
    "    # Spend features\n",
    "    spend_cols = [\"RoomService\",\"FoodCourt\",\"ShoppingMall\",\"Spa\",\"VRDeck\"]\n",
    "    df[\"TotalSpend\"] = df[spend_cols].sum(axis=1, min_count=1)\n",
    "    df[\"LogTotalSpend\"] = np.log1p(df[\"TotalSpend\"])\n",
    "    df[\"AnySpend\"] = df[\"TotalSpend\"].fillna(0) > 0\n",
    "    # Group features (from earlier)\n",
    "    gid_all = pd.concat([train[\"PassengerId\"], test[\"PassengerId\"]], ignore_index=True).str.split(\"_\", n=1, expand=True)[0]\n",
    "    gid_counts = gid_all.value_counts()\n",
    "    gid = df[\"PassengerId\"].str.split(\"_\", n=1, expand=True)[0]\n",
    "    df[\"GroupID\"] = gid\n",
    "    df[\"GroupSize\"] = gid.map(gid_counts).astype(\"Int64\")\n",
    "    df[\"IsAlone\"] = (df[\"GroupSize\"].fillna(1) == 1)\n",
    "    # Age bin (categorical)\n",
    "    bins = [0, 12, 18, 25, 40, 60, 120]\n",
    "    labels = [\"child\",\"teen\",\"youngA\",\"adult\",\"mid\",\"senior\"]\n",
    "    df[\"AgeBin\"] = pd.cut(df[\"Age\"], bins=bins, labels=labels, right=True, include_lowest=True)\n",
    "    # Feature lists\n",
    "    drop_cols = [\"PassengerId\",\"Name\",\"Cabin\",\"Transported\"]\n",
    "    feat_cols = [c for c in df.columns if c not in drop_cols]\n",
    "    cat_cols  = [c for c in feat_cols if df[c].dtype == \"object\" or df[c].dtype == bool]\n",
    "    return df, feat_cols, cat_cols\n",
    "\n",
    "# rebuild\n",
    "train_prep, feat_cols, cat_cols = prepare3(train)\n",
    "test_prep,  _,        _        = prepare3(test)\n",
    "X = train_prep[feat_cols]\n",
    "y = train[\"Transported\"].astype(int)\n",
    "\n",
    "print(\"X shape:\", X.shape, \"| test shape:\", test_prep[feat_cols].shape)\n",
    "print(\"new features present:\", [c for c in [\"LogTotalSpend\",\"AnySpend\",\"AgeBin\"] if c in feat_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e770ebd-9dd7-4f67-9887-5183bf4476e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_categorical: 9 | includes AgeBin? True\n"
     ]
    }
   ],
   "source": [
    "# compute cat_cols to include pandas 'category' dtype\n",
    "def recompute_cat_cols(df, feature_columns):\n",
    "    cats = []\n",
    "    for c in feature_columns:\n",
    "        dt = df[c].dtype\n",
    "        if (dt == 'object') or (dt == bool) or (str(dt) == 'category'):\n",
    "            cats.append(c)\n",
    "    return cats\n",
    "\n",
    "cat_cols = recompute_cat_cols(train_prep, feat_cols)\n",
    "print(\"n_categorical:\", len(cat_cols), \"| includes AgeBin?\", \"AgeBin\" in cat_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96d23fcb-28fb-4eca-9f17-71a507be40f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yosep\\AppData\\Local\\Temp\\ipykernel_20736\\3319599601.py:9: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_cv[c] = X_cv[c].astype(\"object\").fillna(\"Missing\").astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.7349727\ttest: 0.7458309\tbest: 0.7458309 (0)\ttotal: 121ms\tremaining: 4m 2s\n",
      "100:\tlearn: 0.8458441\ttest: 0.8165612\tbest: 0.8228867 (75)\ttotal: 13.7s\tremaining: 4m 16s\n",
      "200:\tlearn: 0.8886972\ttest: 0.8205865\tbest: 0.8246118 (169)\ttotal: 28.2s\tremaining: 4m 12s\n",
      "300:\tlearn: 0.9137187\ttest: 0.8177113\tbest: 0.8251869 (244)\ttotal: 42.8s\tremaining: 4m 1s\n",
      "400:\tlearn: 0.9318378\ttest: 0.8234618\tbest: 0.8251869 (244)\ttotal: 57.2s\tremaining: 3m 48s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.825186889\n",
      "bestIteration = 244\n",
      "\n",
      "Shrink model to first 245 iterations.\n",
      "Fold 1: acc=0.82519, best_iter=244\n",
      "0:\tlearn: 0.7382801\ttest: 0.7326049\tbest: 0.7326049 (0)\ttotal: 76ms\tremaining: 2m 31s\n",
      "100:\tlearn: 0.8518838\ttest: 0.8033353\tbest: 0.8079356 (66)\ttotal: 14.4s\tremaining: 4m 29s\n",
      "200:\tlearn: 0.8912856\ttest: 0.8056354\tbest: 0.8079356 (66)\ttotal: 29s\tremaining: 4m 19s\n",
      "300:\tlearn: 0.9108427\ttest: 0.8073606\tbest: 0.8102358 (240)\ttotal: 43.7s\tremaining: 4m 6s\n",
      "400:\tlearn: 0.9292494\ttest: 0.8085106\tbest: 0.8108108 (396)\ttotal: 58.6s\tremaining: 3m 53s\n",
      "500:\tlearn: 0.9424791\ttest: 0.8073606\tbest: 0.8113859 (404)\ttotal: 1m 13s\tremaining: 3m 40s\n",
      "600:\tlearn: 0.9549899\ttest: 0.8096607\tbest: 0.8113859 (404)\ttotal: 1m 29s\tremaining: 3m 27s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.8113858539\n",
      "bestIteration = 404\n",
      "\n",
      "Shrink model to first 405 iterations.\n",
      "Fold 2: acc=0.81139, best_iter=404\n",
      "0:\tlearn: 0.7364107\ttest: 0.7400805\tbest: 0.7400805 (0)\ttotal: 75.7ms\tremaining: 2m 31s\n",
      "100:\tlearn: 0.8495830\ttest: 0.8102358\tbest: 0.8148361 (35)\ttotal: 14.2s\tremaining: 4m 26s\n",
      "200:\tlearn: 0.8912856\ttest: 0.8102358\tbest: 0.8148361 (35)\ttotal: 28.8s\tremaining: 4m 18s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.8148361127\n",
      "bestIteration = 35\n",
      "\n",
      "Shrink model to first 36 iterations.\n",
      "Fold 3: acc=0.81484, best_iter=35\n",
      "0:\tlearn: 0.7590223\ttest: 0.7548907\tbest: 0.7548907 (0)\ttotal: 138ms\tremaining: 4m 36s\n",
      "100:\tlearn: 0.8418404\ttest: 0.8112773\tbest: 0.8135788 (91)\ttotal: 14s\tremaining: 4m 22s\n",
      "200:\tlearn: 0.8925953\ttest: 0.8181818\tbest: 0.8222094 (185)\ttotal: 28.9s\tremaining: 4m 18s\n",
      "300:\tlearn: 0.9209202\ttest: 0.8199079\tbest: 0.8239356 (259)\ttotal: 44.4s\tremaining: 4m 10s\n",
      "400:\tlearn: 0.9397556\ttest: 0.8199079\tbest: 0.8239356 (259)\ttotal: 59.3s\tremaining: 3m 56s\n",
      "500:\tlearn: 0.9565780\ttest: 0.8199079\tbest: 0.8256617 (460)\ttotal: 1m 14s\tremaining: 3m 42s\n",
      "600:\tlearn: 0.9679367\ttest: 0.8233602\tbest: 0.8262371 (577)\ttotal: 1m 29s\tremaining: 3m 28s\n",
      "700:\tlearn: 0.9761323\ttest: 0.8216341\tbest: 0.8273878 (661)\ttotal: 1m 44s\tremaining: 3m 13s\n",
      "800:\tlearn: 0.9800144\ttest: 0.8181818\tbest: 0.8273878 (661)\ttotal: 1m 59s\tremaining: 2m 58s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.8273878021\n",
      "bestIteration = 661\n",
      "\n",
      "Shrink model to first 662 iterations.\n",
      "Fold 4: acc=0.82739, best_iter=661\n",
      "0:\tlearn: 0.7564342\ttest: 0.7485616\tbest: 0.7485616 (0)\ttotal: 136ms\tremaining: 4m 32s\n",
      "100:\tlearn: 0.8544932\ttest: 0.7957422\tbest: 0.8014960 (66)\ttotal: 14.4s\tremaining: 4m 31s\n",
      "200:\tlearn: 0.8971963\ttest: 0.8032221\tbest: 0.8049482 (147)\ttotal: 29.3s\tremaining: 4m 22s\n",
      "300:\tlearn: 0.9212078\ttest: 0.8066743\tbest: 0.8084005 (291)\ttotal: 44.1s\tremaining: 4m 8s\n",
      "400:\tlearn: 0.9380302\ttest: 0.8014960\tbest: 0.8095512 (340)\ttotal: 59s\tremaining: 3m 55s\n",
      "500:\tlearn: 0.9525521\ttest: 0.8009206\tbest: 0.8095512 (340)\ttotal: 1m 14s\tremaining: 3m 41s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.8095512083\n",
      "bestIteration = 340\n",
      "\n",
      "Shrink model to first 341 iterations.\n",
      "Fold 5: acc=0.80955, best_iter=340\n",
      "\n",
      "CV Accuracy: mean=0.81767, std=0.00727\n",
      "Best iters per fold: [244, 404, 35, 661, 340]\n"
     ]
    }
   ],
   "source": [
    "# 5-fold CV after adding LogTotalSpend / AnySpend / AgeBin\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from catboost import CatBoostClassifier\n",
    "import numpy as np\n",
    "\n",
    "X_cv = X.copy()\n",
    "for c in cat_cols:\n",
    "    X_cv[c] = X_cv[c].astype(\"object\").fillna(\"Missing\").astype(str)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accs, best_ns = [], []\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(skf.split(X_cv, y), 1):\n",
    "    X_tr, X_va = X_cv.iloc[tr_idx], X_cv.iloc[va_idx]\n",
    "    y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "    cat_idx = [X_tr.columns.get_loc(c) for c in cat_cols]\n",
    "\n",
    "    model = CatBoostClassifier(\n",
    "        loss_function=\"Logloss\",\n",
    "        eval_metric=\"Accuracy\",\n",
    "        depth=8,\n",
    "        learning_rate=0.08,\n",
    "        n_estimators=2000,\n",
    "        l2_leaf_reg=3,\n",
    "        random_seed=42,\n",
    "        verbose=100\n",
    "    )\n",
    "    model.fit(\n",
    "        X_tr, y_tr,\n",
    "        cat_features=cat_idx,\n",
    "        eval_set=(X_va, y_va),\n",
    "        use_best_model=True,\n",
    "        early_stopping_rounds=200\n",
    "    )\n",
    "\n",
    "    pred_va = model.predict(X_va)\n",
    "    accs.append(accuracy_score(y_va, pred_va))\n",
    "    best_ns.append(model.get_best_iteration() or model.tree_count_)\n",
    "    print(f\"Fold {fold}: acc={accs[-1]:.5f}, best_iter={best_ns[-1]}\")\n",
    "\n",
    "print(\"\\nCV Accuracy: mean={:.5f}, std={:.5f}\".format(np.mean(accs), np.std(accs)))\n",
    "print(\"Best iters per fold:\", best_ns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "182e9977-76a7-409a-bf2c-26047c48d773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using n_estimators: 340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yosep\\AppData\\Local\\Temp\\ipykernel_20736\\960643911.py:14: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_all[c]  = X_all[c].astype(\"object\").fillna(\"Missing\").astype(str)\n",
      "C:\\Users\\yosep\\AppData\\Local\\Temp\\ipykernel_20736\\960643911.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_test[c] = X_test[c].astype(\"object\").fillna(\"Missing\").astype(str)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId  Transported\n",
       "0     0013_01         True\n",
       "1     0018_01        False\n",
       "2     0019_01         True\n",
       "3     0021_01         True\n",
       "4     0023_01         True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Refit on ALL data using median(best iters) from the last CV and save submission\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "best_n = int(np.median(best_ns))  # uses the best_ns from your last CV cell\n",
    "print(\"Using n_estimators:\", best_n)\n",
    "\n",
    "X_all  = train_prep[feat_cols].copy()\n",
    "X_test = test_prep[feat_cols].copy()\n",
    "\n",
    "# Sanitize categoricals\n",
    "for c in cat_cols:\n",
    "    X_all[c]  = X_all[c].astype(\"object\").fillna(\"Missing\").astype(str)\n",
    "    X_test[c] = X_test[c].astype(\"object\").fillna(\"Missing\").astype(str)\n",
    "\n",
    "cat_idx_all = [X_all.columns.get_loc(c) for c in cat_cols]\n",
    "\n",
    "model_full_bins = CatBoostClassifier(\n",
    "    loss_function=\"Logloss\",\n",
    "    eval_metric=\"Accuracy\",\n",
    "    depth=8,\n",
    "    learning_rate=0.08,\n",
    "    n_estimators=best_n,\n",
    "    l2_leaf_reg=3,\n",
    "    random_seed=42,\n",
    "    verbose=False\n",
    ")\n",
    "model_full_bins.fit(X_all, y, cat_features=cat_idx_all)\n",
    "\n",
    "proba = model_full_bins.predict_proba(X_test)[:, 1]\n",
    "pred_bool = proba >= 0.5\n",
    "\n",
    "sub_bins = pd.DataFrame({\n",
    "    \"PassengerId\": test[\"PassengerId\"],\n",
    "    \"Transported\": pred_bool\n",
    "})\n",
    "sub_bins.to_csv(\"submission_catboost_bins_groups.csv\", index=False)\n",
    "sub_bins.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1558c0ef-908c-40f4-b247-2e959045bc54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CabinNum</td>\n",
       "      <td>12.182749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CabinDeck</td>\n",
       "      <td>8.891193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>VRDeck</td>\n",
       "      <td>7.898089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FoodCourt</td>\n",
       "      <td>7.685353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Spa</td>\n",
       "      <td>7.416362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LogTotalSpend</td>\n",
       "      <td>6.850397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HomePlanet</td>\n",
       "      <td>6.524278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ShoppingMall</td>\n",
       "      <td>5.964700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CabinSide</td>\n",
       "      <td>5.793055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CryoSleep</td>\n",
       "      <td>5.719798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Destination</td>\n",
       "      <td>5.136343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RoomService</td>\n",
       "      <td>4.692038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AgeBin</td>\n",
       "      <td>4.264854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Age</td>\n",
       "      <td>4.247339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TotalSpend</td>\n",
       "      <td>3.073540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GroupID</td>\n",
       "      <td>2.143574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VIP</td>\n",
       "      <td>0.942346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GroupSize</td>\n",
       "      <td>0.522769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>IsAlone</td>\n",
       "      <td>0.050715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AnySpend</td>\n",
       "      <td>0.000508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          feature  importance\n",
       "11       CabinNum   12.182749\n",
       "10      CabinDeck    8.891193\n",
       "9          VRDeck    7.898089\n",
       "6       FoodCourt    7.685353\n",
       "8             Spa    7.416362\n",
       "14  LogTotalSpend    6.850397\n",
       "0      HomePlanet    6.524278\n",
       "7    ShoppingMall    5.964700\n",
       "12      CabinSide    5.793055\n",
       "1       CryoSleep    5.719798\n",
       "2     Destination    5.136343\n",
       "5     RoomService    4.692038\n",
       "19         AgeBin    4.264854\n",
       "3             Age    4.247339\n",
       "13     TotalSpend    3.073540\n",
       "16        GroupID    2.143574\n",
       "4             VIP    0.942346\n",
       "17      GroupSize    0.522769\n",
       "18        IsAlone    0.050715\n",
       "15       AnySpend    0.000508"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show top features from the most recently trained full model\n",
    "import pandas as pd\n",
    "\n",
    "# pick whichever model exists\n",
    "model_candidate = None\n",
    "for name in [\"model_full_bins\", \"model_full_groups\", \"model_full_cv\", \"model_full\"]:\n",
    "    if name in globals():\n",
    "        model_candidate = globals()[name]\n",
    "        break\n",
    "assert model_candidate is not None, \"No trained full model found; run the latest fit cell first.\"\n",
    "\n",
    "# get feature names safely\n",
    "try:\n",
    "    feature_names = list(X_all.columns)\n",
    "except NameError:\n",
    "    feature_names = list(train_prep[feat_cols].columns)\n",
    "\n",
    "imp = model_candidate.get_feature_importance(type=\"FeatureImportance\")\n",
    "fi = pd.DataFrame({\"feature\": feature_names, \"importance\": imp}).sort_values(\"importance\", ascending=False)\n",
    "fi.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abae2667-58f6-4650-822b-8e0e026d1c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yosep\\AppData\\Local\\Temp\\ipykernel_20736\\3779001582.py:45: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_cv[c] = X_cv[c].astype(\"object\").fillna(\"Missing\").astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.7424504\ttest: 0.7567568\tbest: 0.7567568 (0)\ttotal: 152ms\tremaining: 5m 4s\n",
      "100:\tlearn: 0.8528904\ttest: 0.8194365\tbest: 0.8217366 (91)\ttotal: 14.7s\tremaining: 4m 36s\n",
      "200:\tlearn: 0.8990509\ttest: 0.8217366\tbest: 0.8234618 (193)\ttotal: 29.9s\tremaining: 4m 27s\n",
      "300:\tlearn: 0.9275237\ttest: 0.8217366\tbest: 0.8240368 (261)\ttotal: 45.3s\tremaining: 4m 15s\n",
      "400:\tlearn: 0.9459304\ttest: 0.8200115\tbest: 0.8240368 (261)\ttotal: 1m\tremaining: 4m 1s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.8240368028\n",
      "bestIteration = 261\n",
      "\n",
      "Shrink model to first 262 iterations.\n",
      "Fold 1: acc=0.82404, best_iter=261\n",
      "0:\tlearn: 0.7627265\ttest: 0.7498562\tbest: 0.7498562 (0)\ttotal: 137ms\tremaining: 4m 33s\n",
      "100:\tlearn: 0.8629566\ttest: 0.8033353\tbest: 0.8073606 (84)\ttotal: 15s\tremaining: 4m 42s\n",
      "200:\tlearn: 0.8953121\ttest: 0.8131110\tbest: 0.8131110 (180)\ttotal: 30.4s\tremaining: 4m 32s\n",
      "300:\tlearn: 0.9211964\ttest: 0.8154112\tbest: 0.8177113 (271)\ttotal: 46s\tremaining: 4m 19s\n",
      "400:\tlearn: 0.9381651\ttest: 0.8154112\tbest: 0.8194365 (380)\ttotal: 1m 1s\tremaining: 4m 6s\n",
      "500:\tlearn: 0.9532643\ttest: 0.8148361\tbest: 0.8194365 (380)\ttotal: 1m 17s\tremaining: 3m 52s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.8194364577\n",
      "bestIteration = 380\n",
      "\n",
      "Shrink model to first 381 iterations.\n",
      "Fold 2: acc=0.81944, best_iter=380\n",
      "0:\tlearn: 0.7369859\ttest: 0.7366302\tbest: 0.7366302 (0)\ttotal: 135ms\tremaining: 4m 29s\n",
      "100:\tlearn: 0.8616624\ttest: 0.8246118\tbest: 0.8246118 (100)\ttotal: 14.7s\tremaining: 4m 36s\n",
      "200:\tlearn: 0.9032212\ttest: 0.8240368\tbest: 0.8269120 (128)\ttotal: 30s\tremaining: 4m 28s\n",
      "300:\tlearn: 0.9335634\ttest: 0.8297872\tbest: 0.8309373 (261)\ttotal: 45.4s\tremaining: 4m 16s\n",
      "400:\tlearn: 0.9509635\ttest: 0.8343876\tbest: 0.8355377 (397)\ttotal: 1m\tremaining: 4m 1s\n",
      "500:\tlearn: 0.9650561\ttest: 0.8315124\tbest: 0.8355377 (397)\ttotal: 1m 15s\tremaining: 3m 46s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.8355376653\n",
      "bestIteration = 397\n",
      "\n",
      "Shrink model to first 398 iterations.\n",
      "Fold 3: acc=0.83554, best_iter=397\n",
      "0:\tlearn: 0.7698059\ttest: 0.7594937\tbest: 0.7594937 (0)\ttotal: 139ms\tremaining: 4m 38s\n",
      "100:\tlearn: 0.8560748\ttest: 0.8268124\tbest: 0.8273878 (92)\ttotal: 14.3s\tremaining: 4m 28s\n",
      "200:\tlearn: 0.9013659\ttest: 0.8273878\tbest: 0.8296893 (196)\ttotal: 30.1s\tremaining: 4m 29s\n",
      "300:\tlearn: 0.9291157\ttest: 0.8319908\tbest: 0.8360184 (233)\ttotal: 45.5s\tremaining: 4m 16s\n",
      "400:\tlearn: 0.9478073\ttest: 0.8319908\tbest: 0.8360184 (233)\ttotal: 1m 1s\tremaining: 4m 5s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.836018412\n",
      "bestIteration = 233\n",
      "\n",
      "Shrink model to first 234 iterations.\n",
      "Fold 4: acc=0.83602, best_iter=233\n",
      "0:\tlearn: 0.7673616\ttest: 0.7617952\tbest: 0.7617952 (0)\ttotal: 142ms\tremaining: 4m 44s\n",
      "100:\tlearn: 0.8645579\ttest: 0.8078251\tbest: 0.8095512 (93)\ttotal: 15.4s\tremaining: 4m 50s\n",
      "200:\tlearn: 0.9061107\ttest: 0.8049482\tbest: 0.8095512 (93)\ttotal: 31s\tremaining: 4m 37s\n",
      "300:\tlearn: 0.9321352\ttest: 0.8055236\tbest: 0.8112773 (267)\ttotal: 46.7s\tremaining: 4m 23s\n",
      "400:\tlearn: 0.9499641\ttest: 0.8043728\tbest: 0.8112773 (267)\ttotal: 1m 2s\tremaining: 4m 9s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.8112773303\n",
      "bestIteration = 267\n",
      "\n",
      "Shrink model to first 268 iterations.\n",
      "Fold 5: acc=0.81128, best_iter=267\n",
      "\n",
      "CV Accuracy with GroupID_TE: mean=0.82526, std=0.00951\n",
      "Best iters per fold: [261, 380, 397, 233, 267]\n"
     ]
    }
   ],
   "source": [
    "# OOF target mean encoding for GroupID + 5-fold CV\n",
    "import pandas as pd, numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# 1) OOF target-encoding for GroupID (prevents leakage)\n",
    "global_mean = y.mean()\n",
    "train_gid = train_prep[\"GroupID\"].astype(str)\n",
    "test_gid  = test_prep[\"GroupID\"].astype(str)\n",
    "\n",
    "oof_te = pd.Series(np.nan, index=train.index, dtype=float)\n",
    "skf_enc = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for tr_idx, va_idx in skf_enc.split(train_gid, y):\n",
    "    gmeans = pd.DataFrame({\"gid\": train_gid.iloc[tr_idx], \"y\": y.iloc[tr_idx]}).groupby(\"gid\")[\"y\"].mean()\n",
    "    oof_te.iloc[va_idx] = train_gid.iloc[va_idx].map(gmeans)\n",
    "\n",
    "oof_te.fillna(global_mean, inplace=True)\n",
    "gmeans_full = pd.DataFrame({\"gid\": train_gid, \"y\": y}).groupby(\"gid\")[\"y\"].mean()\n",
    "test_te = test_gid.map(gmeans_full).fillna(global_mean)\n",
    "\n",
    "train_prep[\"GroupID_TE\"] = oof_te\n",
    "test_prep[\"GroupID_TE\"]  = test_te\n",
    "\n",
    "# 2) Rebuild matrices\n",
    "drop_cols = [\"PassengerId\",\"Name\",\"Cabin\",\"Transported\"]\n",
    "feat_cols = [c for c in train_prep.columns if c not in drop_cols]\n",
    "\n",
    "def recompute_cat_cols(df, feature_columns):\n",
    "    cats = []\n",
    "    for c in feature_columns:\n",
    "        dt = df[c].dtype\n",
    "        if (dt == \"object\") or (dt == bool) or (str(dt) == \"category\"):\n",
    "            cats.append(c)\n",
    "    return cats\n",
    "\n",
    "cat_cols = recompute_cat_cols(train_prep, feat_cols)\n",
    "\n",
    "X = train_prep[feat_cols]\n",
    "X_test = test_prep[feat_cols]\n",
    "\n",
    "# 3) 5-fold CV with CatBoost\n",
    "X_cv = X.copy()\n",
    "for c in cat_cols:\n",
    "    X_cv[c] = X_cv[c].astype(\"object\").fillna(\"Missing\").astype(str)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accs, best_ns = [], []\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(skf.split(X_cv, y), 1):\n",
    "    X_tr, X_va = X_cv.iloc[tr_idx], X_cv.iloc[va_idx]\n",
    "    y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "    cat_idx = [X_tr.columns.get_loc(c) for c in cat_cols]\n",
    "\n",
    "    model = CatBoostClassifier(\n",
    "        loss_function=\"Logloss\",\n",
    "        eval_metric=\"Accuracy\",\n",
    "        depth=8,\n",
    "        learning_rate=0.08,\n",
    "        n_estimators=2000,\n",
    "        l2_leaf_reg=3,\n",
    "        random_seed=42,\n",
    "        verbose=100\n",
    "    )\n",
    "    model.fit(\n",
    "        X_tr, y_tr,\n",
    "        cat_features=cat_idx,\n",
    "        eval_set=(X_va, y_va),\n",
    "        use_best_model=True,\n",
    "        early_stopping_rounds=200\n",
    "    )\n",
    "\n",
    "    pred_va = model.predict(X_va)\n",
    "    accs.append(accuracy_score(y_va, pred_va))\n",
    "    best_ns.append(model.get_best_iteration() or model.tree_count_)\n",
    "    print(f\"Fold {fold}: acc={accs[-1]:.5f}, best_iter={best_ns[-1]}\")\n",
    "\n",
    "print(\"\\nCV Accuracy with GroupID_TE: mean={:.5f}, std={:.5f}\".format(np.mean(accs), np.std(accs)))\n",
    "print(\"Best iters per fold:\", best_ns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d2f0873-c890-40c2-8e5a-6d29f7527d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using n_estimators: 267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yosep\\AppData\\Local\\Temp\\ipykernel_20736\\5396511.py:14: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_all[c]  = X_all[c].astype(\"object\").fillna(\"Missing\").astype(str)\n",
      "C:\\Users\\yosep\\AppData\\Local\\Temp\\ipykernel_20736\\5396511.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_test[c] = X_test[c].astype(\"object\").fillna(\"Missing\").astype(str)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId  Transported\n",
       "0     0013_01         True\n",
       "1     0018_01        False\n",
       "2     0019_01         True\n",
       "3     0021_01         True\n",
       "4     0023_01         True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Refit using CV-informed trees and GroupID target-encoding; save submission\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "best_n = int(np.median(best_ns))   # e.g., median of [261,380,397,233,267] -> 267\n",
    "print(\"Using n_estimators:\", best_n)\n",
    "\n",
    "X_all  = train_prep[feat_cols].copy()\n",
    "X_test = test_prep[feat_cols].copy()\n",
    "\n",
    "# Sanitize categoricals for CatBoost\n",
    "for c in cat_cols:\n",
    "    X_all[c]  = X_all[c].astype(\"object\").fillna(\"Missing\").astype(str)\n",
    "    X_test[c] = X_test[c].astype(\"object\").fillna(\"Missing\").astype(str)\n",
    "\n",
    "cat_idx_all = [X_all.columns.get_loc(c) for c in cat_cols]\n",
    "\n",
    "model_full_te = CatBoostClassifier(\n",
    "    loss_function=\"Logloss\",\n",
    "    eval_metric=\"Accuracy\",\n",
    "    depth=8,\n",
    "    learning_rate=0.08,\n",
    "    n_estimators=best_n,\n",
    "    l2_leaf_reg=3,\n",
    "    random_seed=42,\n",
    "    verbose=False\n",
    ")\n",
    "model_full_te.fit(X_all, y, cat_features=cat_idx_all)\n",
    "\n",
    "proba = model_full_te.predict_proba(X_test)[:, 1]\n",
    "pred_bool = proba >= 0.5\n",
    "\n",
    "sub_te = pd.DataFrame({\n",
    "    \"PassengerId\": test[\"PassengerId\"],\n",
    "    \"Transported\": pred_bool\n",
    "})\n",
    "sub_te.to_csv(\"submission_catboost_te.csv\", index=False)\n",
    "sub_te.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2eef28e3-cbca-4fbb-81b4-44451b6756a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002374 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2559\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Fold 1: acc=0.82174, best_iter=99\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001162 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2565\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Fold 2: acc=0.81139, best_iter=106\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001908 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2581\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Fold 3: acc=0.80736, best_iter=89\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 3503, number of negative: 3452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001186 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2560\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503666 -> initscore=0.014666\n",
      "[LightGBM] [Info] Start training from score 0.014666\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Fold 4: acc=0.81530, best_iter=104\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 3503, number of negative: 3452\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001526 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2579\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503666 -> initscore=0.014666\n",
      "[LightGBM] [Info] Start training from score 0.014666\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Fold 5: acc=0.79919, best_iter=87\n",
      "\n",
      "LGBM CV: mean=0.81100, std=0.00757\n",
      "Using n_estimators for full LGBM: 99\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 4378, number of negative: 4315\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001845 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2756\n",
      "[LightGBM] [Info] Number of data points in the train set: 8693, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503624 -> initscore=0.014495\n",
      "[LightGBM] [Info] Start training from score 0.014495\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yosep\\AppData\\Local\\Temp\\ipykernel_20736\\1017413020.py:66: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_test_cat[c] = X_test_cat[c].astype(\"object\").fillna(\"Missing\").astype(str)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId  Transported\n",
       "0     0013_01         True\n",
       "1     0018_01        False\n",
       "2     0019_01         True\n",
       "3     0021_01         True\n",
       "4     0023_01         True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LightGBM 5-fold CV on the same features, then blend with CatBoost (model_full_te) and export\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import lightgbm as lgb\n",
    "\n",
    "# 1) Build LGBM-ready matrices (categoricals as 'category' dtype)\n",
    "X_lgb = train_prep[feat_cols].copy()\n",
    "T_lgb = test_prep[feat_cols].copy()\n",
    "for c in cat_cols:\n",
    "    X_lgb[c] = X_lgb[c].astype(\"category\")\n",
    "    T_lgb[c] = T_lgb[c].astype(\"category\")\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accs_lgb, best_iters = [], []\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(skf.split(X_lgb, y), 1):\n",
    "    X_tr, X_va = X_lgb.iloc[tr_idx], X_lgb.iloc[va_idx]\n",
    "    y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "\n",
    "    m = lgb.LGBMClassifier(\n",
    "        objective=\"binary\",\n",
    "        learning_rate=0.06,\n",
    "        num_leaves=64,\n",
    "        feature_fraction=0.9,\n",
    "        bagging_fraction=0.9,\n",
    "        bagging_freq=1,\n",
    "        n_estimators=3000,\n",
    "        random_state=42\n",
    "    )\n",
    "    m.fit(\n",
    "        X_tr, y_tr,\n",
    "        eval_set=[(X_va, y_va)],\n",
    "        eval_metric=\"binary_logloss\",\n",
    "        callbacks=[lgb.early_stopping(200, verbose=False)]\n",
    "    )\n",
    "    best_iters.append(m.best_iteration_)\n",
    "    preds = (m.predict_proba(X_va, num_iteration=m.best_iteration_)[:,1] >= 0.5).astype(int)\n",
    "    acc = accuracy_score(y_va, preds)\n",
    "    accs_lgb.append(acc)\n",
    "    print(f\"Fold {fold}: acc={acc:.5f}, best_iter={m.best_iteration_}\")\n",
    "\n",
    "print(\"\\nLGBM CV: mean={:.5f}, std={:.5f}\".format(np.mean(accs_lgb), np.std(accs_lgb)))\n",
    "best_n_lgb = int(np.median(best_iters))\n",
    "print(\"Using n_estimators for full LGBM:\", best_n_lgb)\n",
    "\n",
    "# 2) Refit LGBM on ALL data\n",
    "m_lgb_full = lgb.LGBMClassifier(\n",
    "    objective=\"binary\",\n",
    "    learning_rate=0.06,\n",
    "    num_leaves=64,\n",
    "    feature_fraction=0.9,\n",
    "    bagging_fraction=0.9,\n",
    "    bagging_freq=1,\n",
    "    n_estimators=best_n_lgb,\n",
    "    random_state=42\n",
    ")\n",
    "m_lgb_full.fit(X_lgb, y)\n",
    "proba_lgb = m_lgb_full.predict_proba(T_lgb)[:,1]\n",
    "\n",
    "# 3) Get CatBoost test probabilities from the latest full model (model_full_te if present, else fall back)\n",
    "def cat_proba_on_test():\n",
    "    # build CatBoost-style matrices (categoricals as strings, NaNs -> \"Missing\")\n",
    "    X_test_cat = test_prep[feat_cols].copy()\n",
    "    for c in cat_cols:\n",
    "        X_test_cat[c] = X_test_cat[c].astype(\"object\").fillna(\"Missing\").astype(str)\n",
    "    # prefer model_full_te; fall back to model_full_bins/model_full_groups/model_full_cv/model_full\n",
    "    for name in [\"model_full_te\", \"model_full_bins\", \"model_full_groups\", \"model_full_cv\", \"model_full\"]:\n",
    "        if name in globals():\n",
    "            return globals()[name].predict_proba(X_test_cat)[:,1]\n",
    "    raise RuntimeError(\"No CatBoost full model found. Re-run a full CatBoost fit cell.\")\n",
    "\n",
    "proba_cat = cat_proba_on_test()\n",
    "\n",
    "# 4) Simple 50/50 blend and export\n",
    "proba_blend = 0.5 * proba_cat + 0.5 * proba_lgb\n",
    "pred_bool = proba_blend >= 0.5\n",
    "\n",
    "sub_blend = pd.DataFrame({\"PassengerId\": test[\"PassengerId\"], \"Transported\": pred_bool})\n",
    "sub_blend.to_csv(\"submission_blend_cat_lgb.csv\", index=False)\n",
    "sub_blend.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82b4c4f4-5847-47c7-8acf-059f98eb637e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yosep\\AppData\\Local\\Temp\\ipykernel_20736\\3007573837.py:15: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_cb[c] = X_cb[c].astype(\"object\").fillna(\"Missing\").astype(str)\n",
      "C:\\Users\\yosep\\AppData\\Local\\Temp\\ipykernel_20736\\3007573837.py:16: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  T_cb[c] = T_cb[c].astype(\"object\").fillna(\"Missing\").astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001495 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2559\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001472 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2565\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 3502, number of negative: 3452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001664 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2581\n",
      "[LightGBM] [Info] Number of data points in the train set: 6954, number of used features: 21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503595 -> initscore=0.014380\n",
      "[LightGBM] [Info] Start training from score 0.014380\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 3503, number of negative: 3452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001514 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2560\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503666 -> initscore=0.014666\n",
      "[LightGBM] [Info] Start training from score 0.014666\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 3503, number of negative: 3452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001661 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2579\n",
      "[LightGBM] [Info] Number of data points in the train set: 6955, number of used features: 21\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503666 -> initscore=0.014666\n",
      "[LightGBM] [Info] Start training from score 0.014666\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Best alpha (CatBoost weight): 0.68\n",
      "OOF accuracy at best alpha: 0.82365\n"
     ]
    }
   ],
   "source": [
    "# Optimize blend weight alpha for CatBoost + LightGBM using 5-fold OOF predictions\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "y_arr = y.values\n",
    "\n",
    "# 1) Build CatBoost-friendly and LGB-friendly matrices\n",
    "X_cb = train_prep[feat_cols].copy()\n",
    "T_cb = test_prep[feat_cols].copy()\n",
    "for c in cat_cols:\n",
    "    X_cb[c] = X_cb[c].astype(\"object\").fillna(\"Missing\").astype(str)\n",
    "    T_cb[c] = T_cb[c].astype(\"object\").fillna(\"Missing\").astype(str)\n",
    "\n",
    "X_lgb = train_prep[feat_cols].copy()\n",
    "T_lgb = test_prep[feat_cols].copy()\n",
    "for c in cat_cols:\n",
    "    X_lgb[c] = X_lgb[c].astype(\"category\")\n",
    "    T_lgb[c] = T_lgb[c].astype(\"category\")\n",
    "\n",
    "# 2) OOF probabilities for both models\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "oof_cat = np.zeros(len(X_cb))\n",
    "oof_lgb = np.zeros(len(X_lgb))\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(skf.split(X_cb, y_arr), 1):\n",
    "    # CatBoost\n",
    "    cat_idx = [X_cb.columns.get_loc(c) for c in cat_cols]\n",
    "    m_cb = CatBoostClassifier(\n",
    "        loss_function=\"Logloss\",\n",
    "        eval_metric=\"Accuracy\",\n",
    "        depth=8,\n",
    "        learning_rate=0.08,\n",
    "        n_estimators=2000,\n",
    "        l2_leaf_reg=3,\n",
    "        random_seed=42,\n",
    "        verbose=False\n",
    "    )\n",
    "    m_cb.fit(X_cb.iloc[tr_idx], y_arr[tr_idx], cat_features=cat_idx,\n",
    "             eval_set=(X_cb.iloc[va_idx], y_arr[va_idx]), use_best_model=True, early_stopping_rounds=200)\n",
    "    oof_cat[va_idx] = m_cb.predict_proba(X_cb.iloc[va_idx])[:,1]\n",
    "\n",
    "    # LightGBM\n",
    "    m_lgb = lgb.LGBMClassifier(\n",
    "        objective=\"binary\",\n",
    "        learning_rate=0.06,\n",
    "        num_leaves=64,\n",
    "        feature_fraction=0.9,\n",
    "        bagging_fraction=0.9,\n",
    "        bagging_freq=1,\n",
    "        n_estimators=3000,\n",
    "        random_state=42\n",
    "    )\n",
    "    m_lgb.fit(X_lgb.iloc[tr_idx], y_arr[tr_idx],\n",
    "              eval_set=[(X_lgb.iloc[va_idx], y_arr[va_idx])],\n",
    "              eval_metric=\"binary_logloss\",\n",
    "              callbacks=[lgb.early_stopping(200, verbose=False)])\n",
    "    oof_lgb[va_idx] = m_lgb.predict_proba(X_lgb.iloc[va_idx], num_iteration=m_lgb.best_iteration_)[:,1]\n",
    "\n",
    "# 3) Search alpha in [0.30 .. 0.70] to maximize CV accuracy\n",
    "alphas = np.linspace(0.30, 0.70, 41)  # step 0.01\n",
    "best_alpha, best_acc = 0.50, accuracy_score(y_arr, (0.5*oof_cat + 0.5*oof_lgb >= 0.5).astype(int))\n",
    "for a in alphas:\n",
    "    acc = accuracy_score(y_arr, ((a*oof_cat + (1-a)*oof_lgb) >= 0.5).astype(int))\n",
    "    if acc > best_acc:\n",
    "        best_alpha, best_acc = float(a), acc\n",
    "\n",
    "print(f\"Best alpha (CatBoost weight): {best_alpha:.2f}\")\n",
    "print(f\"OOF accuracy at best alpha: {best_acc:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "226efe3d-dc7b-4f18-bbb1-5934e0ab0778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Saved: submission_blend_alpha_68.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId  Transported\n",
       "0     0013_01         True\n",
       "1     0018_01        False\n",
       "2     0019_01         True\n",
       "3     0021_01         True\n",
       "4     0023_01         True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use alpha = 0.68 (CatBoost weight) to blend CatBoost + LightGBM and export submission\n",
    "import numpy as np, pandas as pd\n",
    "import lightgbm as lgb\n",
    "\n",
    "alpha = 0.68  # from the OOF search\n",
    "\n",
    "# Ensure CatBoost-style test matrix exists\n",
    "try:\n",
    "    T_cb\n",
    "except NameError:\n",
    "    T_cb = test_prep[feat_cols].copy()\n",
    "    for c in cat_cols:\n",
    "        T_cb[c] = T_cb[c].astype(\"object\").fillna(\"Missing\").astype(str)\n",
    "\n",
    "# Ensure LGBM-style test matrix exists\n",
    "try:\n",
    "    T_lgb\n",
    "except NameError:\n",
    "    T_lgb = test_prep[feat_cols].copy()\n",
    "    for c in cat_cols:\n",
    "        T_lgb[c] = T_lgb[c].astype(\"category\")\n",
    "\n",
    "# 1) CatBoost probabilities (use the best full model we trained)\n",
    "assert \"model_full_te\" in globals(), \"Run the cell that fits model_full_te first.\"\n",
    "proba_cat = model_full_te.predict_proba(T_cb)[:, 1]\n",
    "\n",
    "# 2) LightGBM full model — reuse if available, otherwise fit quickly\n",
    "if \"m_lgb_full\" not in globals():\n",
    "    # quick CV to pick a sensible n_estimators, then refit full\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    X_lgb = train_prep[feat_cols].copy()\n",
    "    for c in cat_cols:\n",
    "        X_lgb[c] = X_lgb[c].astype(\"category\")\n",
    "    y_arr = y.values\n",
    "    iters = []\n",
    "    for tr, va in skf.split(X_lgb, y_arr):\n",
    "        m = lgb.LGBMClassifier(\n",
    "            objective=\"binary\",\n",
    "            learning_rate=0.06,\n",
    "            num_leaves=64,\n",
    "            feature_fraction=0.9,\n",
    "            bagging_fraction=0.9,\n",
    "            bagging_freq=1,\n",
    "            n_estimators=3000,\n",
    "            random_state=42\n",
    "        )\n",
    "        m.fit(X_lgb.iloc[tr], y_arr[tr],\n",
    "              eval_set=[(X_lgb.iloc[va], y_arr[va])],\n",
    "              eval_metric=\"binary_logloss\",\n",
    "              callbacks=[lgb.early_stopping(200, verbose=False)])\n",
    "        iters.append(m.best_iteration_ or 300)\n",
    "    best_n_lgb = int(np.median(iters))\n",
    "    m_lgb_full = lgb.LGBMClassifier(\n",
    "        objective=\"binary\",\n",
    "        learning_rate=0.06,\n",
    "        num_leaves=64,\n",
    "        feature_fraction=0.9,\n",
    "        bagging_fraction=0.9,\n",
    "        bagging_freq=1,\n",
    "        n_estimators=best_n_lgb,\n",
    "        random_state=42\n",
    "    )\n",
    "    m_lgb_full.fit(train_prep[feat_cols].astype({c:\"category\" for c in cat_cols}), y)\n",
    "\n",
    "proba_lgb = m_lgb_full.predict_proba(T_lgb)[:, 1]\n",
    "\n",
    "# 3) Alpha-weighted blend and save\n",
    "proba_blend = alpha * proba_cat + (1 - alpha) * proba_lgb\n",
    "pred_bool = proba_blend >= 0.5\n",
    "\n",
    "sub_alpha = pd.DataFrame({\n",
    "    \"PassengerId\": test[\"PassengerId\"],\n",
    "    \"Transported\": pred_bool\n",
    "})\n",
    "fname = f\"submission_blend_alpha_{int(alpha*100):02d}.csv\"  # e.g., 68 -> submission_blend_alpha_68.csv\n",
    "sub_alpha.to_csv(fname, index=False)\n",
    "print(\"Saved:\", fname)\n",
    "sub_alpha.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc89de53-2f12-499a-9621-4c1463a47ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stack OOF acc: 0.8238812837915565\n",
      "Meta weights (CatBoost, LightGBM): [4.16347131 1.88300188] intercept: [-2.93603347]\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yosep\\AppData\\Local\\Temp\\ipykernel_20736\\224160845.py:79: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  T_cb[c] = T_cb[c].astype(\"object\").fillna(\"Missing\").astype(str)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId  Transported\n",
       "0     0013_01         True\n",
       "1     0018_01        False\n",
       "2     0019_01         True\n",
       "3     0021_01         True\n",
       "4     0023_01         True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stacking: train a LogisticRegression meta-model on OOF probs of CatBoost + LightGBM,\n",
    "# then predict on test and write a submission.\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "y_arr = y.values\n",
    "\n",
    "# --- Ensure we have OOF probabilities for both models ---\n",
    "need_oof = ('oof_cat' not in globals()) or ('oof_lgb' not in globals())\n",
    "\n",
    "if need_oof:\n",
    "    print(\"Recomputing OOF predictions for stacking...\")\n",
    "    # CatBoost-friendly matrices\n",
    "    X_cb = train_prep[feat_cols].copy()\n",
    "    for c in cat_cols:\n",
    "        X_cb[c] = X_cb[c].astype(\"object\").fillna(\"Missing\").astype(str)\n",
    "    # LightGBM-friendly matrices\n",
    "    X_lgb = train_prep[feat_cols].copy()\n",
    "    for c in cat_cols:\n",
    "        X_lgb[c] = X_lgb[c].astype(\"category\")\n",
    "\n",
    "    oof_cat = np.zeros(len(X_cb))\n",
    "    oof_lgb = np.zeros(len(X_lgb))\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    for tr_idx, va_idx in skf.split(X_cb, y_arr):\n",
    "        # CatBoost fold\n",
    "        cat_idx = [X_cb.columns.get_loc(c) for c in cat_cols]\n",
    "        m_cb = CatBoostClassifier(\n",
    "            loss_function=\"Logloss\",\n",
    "            eval_metric=\"Accuracy\",\n",
    "            depth=8,\n",
    "            learning_rate=0.08,\n",
    "            n_estimators=2000,\n",
    "            l2_leaf_reg=3,\n",
    "            random_seed=42,\n",
    "            verbose=False\n",
    "        )\n",
    "        m_cb.fit(X_cb.iloc[tr_idx], y_arr[tr_idx], cat_features=cat_idx,\n",
    "                 eval_set=(X_cb.iloc[va_idx], y_arr[va_idx]),\n",
    "                 use_best_model=True, early_stopping_rounds=200)\n",
    "        oof_cat[va_idx] = m_cb.predict_proba(X_cb.iloc[va_idx])[:,1]\n",
    "\n",
    "        # LightGBM fold\n",
    "        m_lgb = lgb.LGBMClassifier(\n",
    "            objective=\"binary\",\n",
    "            learning_rate=0.06,\n",
    "            num_leaves=64,\n",
    "            feature_fraction=0.9,\n",
    "            bagging_fraction=0.9,\n",
    "            bagging_freq=1,\n",
    "            n_estimators=3000,\n",
    "            random_state=42\n",
    "        )\n",
    "        m_lgb.fit(X_lgb.iloc[tr_idx], y_arr[tr_idx],\n",
    "                  eval_set=[(X_lgb.iloc[va_idx], y_arr[va_idx])],\n",
    "                  eval_metric=\"binary_logloss\",\n",
    "                  callbacks=[lgb.early_stopping(200, verbose=False)])\n",
    "        oof_lgb[va_idx] = m_lgb.predict_proba(X_lgb.iloc[va_idx], num_iteration=m_lgb.best_iteration_)[:,1]\n",
    "\n",
    "# --- Train meta-model on OOF probs ---\n",
    "X_meta = np.column_stack([oof_cat, oof_lgb])\n",
    "meta = LogisticRegression(max_iter=1000)\n",
    "meta.fit(X_meta, y_arr)\n",
    "oof_meta = meta.predict_proba(X_meta)[:,1]\n",
    "print(\"Stack OOF acc:\", accuracy_score(y_arr, (oof_meta >= 0.5).astype(int)))\n",
    "print(\"Meta weights (CatBoost, LightGBM):\", meta.coef_.ravel(), \"intercept:\", meta.intercept_)\n",
    "\n",
    "# --- Prepare test probs from our fitted full models ---\n",
    "# CatBoost test probs\n",
    "if 'model_full_te' in globals():\n",
    "    T_cb = test_prep[feat_cols].copy()\n",
    "    for c in cat_cols:\n",
    "        T_cb[c] = T_cb[c].astype(\"object\").fillna(\"Missing\").astype(str)\n",
    "    P_cat = model_full_te.predict_proba(T_cb)[:,1]\n",
    "else:\n",
    "    raise RuntimeError(\"Run the cell that fits model_full_te first.\")\n",
    "\n",
    "# LightGBM test probs (reuse m_lgb_full if we already trained it)\n",
    "if 'm_lgb_full' in globals():\n",
    "    T_lgb = test_prep[feat_cols].copy()\n",
    "    for c in cat_cols:\n",
    "        T_lgb[c] = T_lgb[c].astype(\"category\")\n",
    "    P_lgb = m_lgb_full.predict_proba(T_lgb)[:,1]\n",
    "else:\n",
    "    # quick fit if not present\n",
    "    T_lgb = test_prep[feat_cols].copy()\n",
    "    for c in cat_cols:\n",
    "        T_lgb[c] = T_lgb[c].astype(\"category\")\n",
    "    m_lgb_full = lgb.LGBMClassifier(\n",
    "        objective=\"binary\", learning_rate=0.06, num_leaves=64,\n",
    "        feature_fraction=0.9, bagging_fraction=0.9, bagging_freq=1,\n",
    "        n_estimators=300, random_state=42\n",
    "    )\n",
    "    m_lgb_full.fit(train_prep[feat_cols].astype({c:\"category\" for c in cat_cols}), y)\n",
    "    P_lgb = m_lgb_full.predict_proba(T_lgb)[:,1]\n",
    "\n",
    "# --- Meta predictions on test ---\n",
    "X_test_meta = np.column_stack([P_cat, P_lgb])\n",
    "proba_stack = meta.predict_proba(X_test_meta)[:,1]\n",
    "pred_bool = proba_stack >= 0.5\n",
    "\n",
    "sub_stack = pd.DataFrame({\"PassengerId\": test[\"PassengerId\"], \"Transported\": pred_bool})\n",
    "sub_stack.to_csv(\"submission_stack_lr_cat_lgb.csv\", index=False)\n",
    "sub_stack.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0470bf9c-3a3e-451f-99ba-7b96a2221ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yosep\\AppData\\Local\\Temp\\ipykernel_20736\\1369620394.py:38: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[c] = X[c].astype(\"object\").fillna(\"Missing\").astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.7532355\ttest: 0.7579068\tbest: 0.7579068 (0)\ttotal: 166ms\tremaining: 5m 32s\n",
      "100:\tlearn: 0.8530342\ttest: 0.8240368\tbest: 0.8251869 (99)\ttotal: 15.6s\tremaining: 4m 53s\n",
      "200:\tlearn: 0.9062410\ttest: 0.8280621\tbest: 0.8332375 (170)\ttotal: 31.7s\tremaining: 4m 44s\n",
      "300:\tlearn: 0.9351452\ttest: 0.8315124\tbest: 0.8332375 (170)\ttotal: 48s\tremaining: 4m 31s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.8332374928\n",
      "bestIteration = 170\n",
      "\n",
      "Shrink model to first 171 iterations.\n",
      "0:\tlearn: 0.7704918\ttest: 0.7521564\tbest: 0.7521564 (0)\ttotal: 193ms\tremaining: 6m 25s\n",
      "100:\tlearn: 0.8661202\ttest: 0.8102358\tbest: 0.8131110 (97)\ttotal: 16.3s\tremaining: 5m 5s\n",
      "200:\tlearn: 0.9035088\ttest: 0.8182864\tbest: 0.8194365 (197)\ttotal: 32.3s\tremaining: 4m 49s\n",
      "300:\tlearn: 0.9279551\ttest: 0.8148361\tbest: 0.8194365 (197)\ttotal: 48.4s\tremaining: 4m 33s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.8194364577\n",
      "bestIteration = 197\n",
      "\n",
      "Shrink model to first 198 iterations.\n",
      "0:\tlearn: 0.7658901\ttest: 0.7648074\tbest: 0.7648074 (0)\ttotal: 147ms\tremaining: 4m 53s\n",
      "100:\tlearn: 0.8597929\ttest: 0.8217366\tbest: 0.8263370 (82)\ttotal: 15.4s\tremaining: 4m 49s\n",
      "200:\tlearn: 0.9050906\ttest: 0.8251869\tbest: 0.8297872 (145)\ttotal: 31.5s\tremaining: 4m 41s\n",
      "300:\tlearn: 0.9328444\ttest: 0.8148361\tbest: 0.8297872 (145)\ttotal: 47.7s\tremaining: 4m 29s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.829787234\n",
      "bestIteration = 145\n",
      "\n",
      "Shrink model to first 146 iterations.\n",
      "0:\tlearn: 0.7580158\ttest: 0.7543153\tbest: 0.7543153 (0)\ttotal: 109ms\tremaining: 3m 37s\n",
      "100:\tlearn: 0.8552121\ttest: 0.8239356\tbest: 0.8273878 (89)\ttotal: 15.4s\tremaining: 4m 49s\n",
      "200:\tlearn: 0.9032351\ttest: 0.8222094\tbest: 0.8273878 (89)\ttotal: 31.5s\tremaining: 4m 41s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.8273878021\n",
      "bestIteration = 89\n",
      "\n",
      "Shrink model to first 90 iterations.\n",
      "0:\tlearn: 0.7564342\ttest: 0.7474108\tbest: 0.7474108 (0)\ttotal: 100ms\tremaining: 3m 20s\n",
      "100:\tlearn: 0.8605320\ttest: 0.8014960\tbest: 0.8060990 (86)\ttotal: 15.4s\tremaining: 4m 49s\n",
      "200:\tlearn: 0.9052480\ttest: 0.8032221\tbest: 0.8107020 (156)\ttotal: 31.1s\tremaining: 4m 38s\n",
      "300:\tlearn: 0.9332854\ttest: 0.8020713\tbest: 0.8107020 (156)\ttotal: 47.4s\tremaining: 4m 27s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.8107019563\n",
      "bestIteration = 156\n",
      "\n",
      "Shrink model to first 157 iterations.\n"
     ]
    }
   ],
   "source": [
    "# === Adding a few light interaction features ===\n",
    "import pandas as pd\n",
    "def add_interactions(df):\n",
    "    # 1) Deck+Side combo (captures location on ship)\n",
    "    df[\"DeckSide\"] = (df[\"CabinDeck\"].astype(str) + \"_\" + df[\"CabinSide\"].astype(str)).astype(\"category\")\n",
    "    # 2) HomePlanet + Destination combo (routes)\n",
    "    df[\"HP_Dest\"] = (df[\"HomePlanet\"].astype(str) + \"_\" + df[\"Destination\"].astype(str)).astype(\"category\")\n",
    "    # 3) Cabin number quantile bin (coarse location bucket)\n",
    "    df[\"CabinNumBin\"] = pd.qcut(df[\"CabinNum\"], q=10, labels=False, duplicates=\"drop\")\n",
    "    df[\"CabinNumBin\"] = df[\"CabinNumBin\"].astype(\"category\")\n",
    "    return df\n",
    "\n",
    "train_prep = add_interactions(train_prep)\n",
    "test_prep  = add_interactions(test_prep)\n",
    "\n",
    "# === Rebuild feature list & categorical list ===\n",
    "drop_cols = [\"PassengerId\",\"Name\",\"Cabin\",\"Transported\"]\n",
    "feat_cols = [c for c in train_prep.columns if c not in drop_cols]\n",
    "\n",
    "def recompute_cat_cols(df, feature_columns):\n",
    "    cats = []\n",
    "    for c in feature_columns:\n",
    "        dt = df[c].dtype\n",
    "        if (dt == \"object\") or (dt == bool) or (str(dt) == \"category\"):\n",
    "            cats.append(c)\n",
    "    return cats\n",
    "\n",
    "cat_cols = recompute_cat_cols(train_prep, feat_cols)\n",
    "\n",
    "# === 5-fold CV with CatBoost (same params as before) ===\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from catboost import CatBoostClassifier\n",
    "import numpy as np\n",
    "\n",
    "X = train_prep[feat_cols].copy()\n",
    "for c in cat_cols:\n",
    "    X[c] = X[c].astype(\"object\").fillna(\"Missing\").astype(str)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accs, best_ns = [], []\n",
    "\n",
    "for fold, (tr_idx, va_idx) in enumerate(skf.split(X, y), 1):\n",
    "    X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "    y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
    "    cat_idx = [X_tr.columns.get_loc(c) for c in cat_cols]\n",
    "\n",
    "    model = CatBoostClassifier(\n",
    "        loss_function=\"Logloss\",\n",
    "        eval_metric=\"Accuracy\",\n",
    "        depth=8,\n",
    "        learning_rate=0.08,\n",
    "        n_estimators=2000,\n",
    "        l2_leaf_reg=3,\n",
    "        random_seed=42,\n",
    "        verbose=100\n",
    "    )\n",
    "    model.fit(\n",
    "        X_tr, y_tr,\n",
    "        cat_features=cat_idx,\n",
    "        eval_set=(X_va, y_va),\n",
    "        use_best_model=True,\n",
    "        early_stopping_rounds=200\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a95d3b6-1819-4e93-a2ee-ec11e542d210",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yosep\\anaconda3\\envs\\stitanic\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:3860: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\yosep\\anaconda3\\envs\\stitanic\\Lib\\site-packages\\numpy\\_core\\_methods.py:144: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcatboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CatBoostClassifier\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m best_n = \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmedian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_ns\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# use the median of the best iterations from the CV you just ran\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mUsing n_estimators:\u001b[39m\u001b[33m\"\u001b[39m, best_n)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Build full train/test matrices and sanitize categoricals for CatBoost\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "# Refit CatBoost on ALL data using the new interactions (DeckSide, HP_Dest, CabinNumBin)\n",
    "# Use the CV-derived best number of trees\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "best_n = int(np.median(best_ns))  # use the median of the best iterations from the CV you just ran\n",
    "print(\"Using n_estimators:\", best_n)\n",
    "\n",
    "# Build full train/test matrices and sanitize categoricals for CatBoost\n",
    "X_all  = train_prep[feat_cols].copy()\n",
    "X_test = test_prep[feat_cols].copy()\n",
    "for c in cat_cols:\n",
    "    X_all[c]  = X_all[c].astype(\"object\").fillna(\"Missing\").astype(str)\n",
    "    X_test[c] = X_test[c].astype(\"object\").fillna(\"Missing\").astype(str)\n",
    "\n",
    "cat_idx_all = [X_all.columns.get_loc(c) for c in cat_cols]\n",
    "\n",
    "model_full_inter = CatBoostClassifier(\n",
    "    loss_function=\"Logloss\",\n",
    "    eval_metric=\"Accuracy\",\n",
    "    depth=8,\n",
    "    learning_rate=0.08,\n",
    "    n_estimators=best_n,\n",
    "    l2_leaf_reg=3,\n",
    "    random_seed=42,\n",
    "    verbose=False\n",
    ")\n",
    "model_full_inter.fit(X_all, y, cat_features=cat_idx_all)\n",
    "\n",
    "proba = model_full_inter.predict_proba(X_test)[:, 1]\n",
    "pred_bool = proba >= 0.5\n",
    "\n",
    "sub_inter = pd.DataFrame({\n",
    "    \"PassengerId\": test[\"PassengerId\"],\n",
    "    \"Transported\": pred_bool\n",
    "})\n",
    "sub_inter.to_csv(\"submission_catboost_interactions.csv\", index=False)\n",
    "sub_inter.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c6aa0a1-4dcb-43ee-b631-c9b818c425a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using n_estimators: 170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yosep\\AppData\\Local\\Temp\\ipykernel_20736\\1169899717.py:26: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_all[c]  = X_all[c].astype(\"object\").fillna(\"Missing\").astype(str)\n",
      "C:\\Users\\yosep\\AppData\\Local\\Temp\\ipykernel_20736\\1169899717.py:27: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_test[c] = X_test[c].astype(\"object\").fillna(\"Missing\").astype(str)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId  Transported\n",
       "0     0013_01         True\n",
       "1     0018_01        False\n",
       "2     0019_01         True\n",
       "3     0021_01         True\n",
       "4     0023_01         True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Refit CatBoost on ALL data with interaction features, using CV median if available,\n",
    "# otherwise fall back to a solid default.\n",
    "import numpy as np, pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# 1) pick n_estimators safely\n",
    "fallback_best_n = 170  # good default based on your recent CV logs\n",
    "if 'best_ns' in globals() and isinstance(best_ns, (list, tuple)) and len(best_ns) > 0:\n",
    "    med = float(np.nanmedian(best_ns))\n",
    "    best_n = int(med) if np.isfinite(med) else fallback_best_n\n",
    "else:\n",
    "    best_n = fallback_best_n\n",
    "\n",
    "print(\"Using n_estimators:\", best_n)\n",
    "\n",
    "# 2) build matrices\n",
    "X_all  = train_prep[feat_cols].copy()\n",
    "X_test = test_prep[feat_cols].copy()\n",
    "cat_cols_current = []\n",
    "for c in feat_cols:\n",
    "    dt = X_all[c].dtype\n",
    "    if (dt == \"object\") or (dt == bool) or (str(dt) == \"category\"):\n",
    "        cat_cols_current.append(c)\n",
    "\n",
    "for c in cat_cols_current:\n",
    "    X_all[c]  = X_all[c].astype(\"object\").fillna(\"Missing\").astype(str)\n",
    "    X_test[c] = X_test[c].astype(\"object\").fillna(\"Missing\").astype(str)\n",
    "\n",
    "cat_idx_all = [X_all.columns.get_loc(c) for c in cat_cols_current]\n",
    "\n",
    "# 3) fit full model\n",
    "model_full_inter = CatBoostClassifier(\n",
    "    loss_function=\"Logloss\",\n",
    "    eval_metric=\"Accuracy\",\n",
    "    depth=8,\n",
    "    learning_rate=0.08,\n",
    "    n_estimators=best_n,\n",
    "    l2_leaf_reg=3,\n",
    "    random_seed=42,\n",
    "    verbose=False\n",
    ")\n",
    "model_full_inter.fit(X_all, y, cat_features=cat_idx_all)\n",
    "\n",
    "# 4) predict & save\n",
    "proba = model_full_inter.predict_proba(X_test)[:, 1]\n",
    "pred_bool = proba >= 0.5\n",
    "\n",
    "sub_inter = pd.DataFrame({\n",
    "    \"PassengerId\": test[\"PassengerId\"],\n",
    "    \"Transported\": pred_bool\n",
    "})\n",
    "sub_inter.to_csv(\"submission_catboost_interactions.csv\", index=False)\n",
    "sub_inter.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "039d926b-5539-439f-953c-f7380c66ce43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yosep\\AppData\\Local\\Temp\\ipykernel_20736\\474211646.py:30: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_cb[c] = X_cb[c].astype(\"object\").fillna(\"Missing\").astype(str)\n",
      "C:\\Users\\yosep\\AppData\\Local\\Temp\\ipykernel_20736\\474211646.py:31: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  T_cb[c] = T_cb[c].astype(\"object\").fillna(\"Missing\").astype(str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 4378, number of negative: 4315\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001574 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2756\n",
      "[LightGBM] [Info] Number of data points in the train set: 8693, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503624 -> initscore=0.014495\n",
      "[LightGBM] [Info] Start training from score 0.014495\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 4378, number of negative: 4315\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001258 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2756\n",
      "[LightGBM] [Info] Number of data points in the train set: 8693, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503624 -> initscore=0.014495\n",
      "[LightGBM] [Info] Start training from score 0.014495\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Info] Number of positive: 4378, number of negative: 4315\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001873 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2756\n",
      "[LightGBM] [Info] Number of data points in the train set: 8693, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.503624 -> initscore=0.014495\n",
      "[LightGBM] [Info] Start training from score 0.014495\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Saved: submission_seed_ens_blend_3x.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId  Transported\n",
       "0     0013_01         True\n",
       "1     0018_01        False\n",
       "2     0019_01         True\n",
       "3     0021_01         True\n",
       "4     0023_01         True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seed-averaged CatBoost + LightGBM, dropping bad interaction cols, then 50/50 blend\n",
    "import numpy as np, pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "# 0) drop the interaction columns if they exist (they hurt LB)\n",
    "bad_cols = [\"DeckSide\", \"HP_Dest\", \"CabinNumBin\"]\n",
    "train_ens = train_prep.drop(columns=[c for c in bad_cols if c in train_prep.columns]).copy()\n",
    "test_ens  = test_prep.drop(columns=[c for c in bad_cols if c in test_prep.columns]).copy()\n",
    "\n",
    "drop_cols = [\"PassengerId\",\"Name\",\"Cabin\",\"Transported\"]\n",
    "feat_ens = [c for c in train_ens.columns if c not in drop_cols]\n",
    "\n",
    "# rebuild cat list from dtypes\n",
    "def get_cat_cols(df, cols):\n",
    "    out = []\n",
    "    for c in cols:\n",
    "        dt = df[c].dtype\n",
    "        if (dt == \"object\") or (dt == bool) or (str(dt) == \"category\"):\n",
    "            out.append(c)\n",
    "    return out\n",
    "\n",
    "cat_cols_ens = get_cat_cols(train_ens, feat_ens)\n",
    "\n",
    "# 1) matrices for each library\n",
    "# CatBoost expects strings for categorical\n",
    "X_cb = train_ens[feat_ens].copy()\n",
    "T_cb = test_ens[feat_ens].copy()\n",
    "for c in cat_cols_ens:\n",
    "    X_cb[c] = X_cb[c].astype(\"object\").fillna(\"Missing\").astype(str)\n",
    "    T_cb[c] = T_cb[c].astype(\"object\").fillna(\"Missing\").astype(str)\n",
    "cat_idx = [X_cb.columns.get_loc(c) for c in cat_cols_ens]\n",
    "\n",
    "# LightGBM expects category dtype\n",
    "X_lgb = train_ens[feat_ens].copy()\n",
    "T_lgb = test_ens[feat_ens].copy()\n",
    "for c in cat_cols_ens:\n",
    "    X_lgb[c] = X_lgb[c].astype(\"category\")\n",
    "    T_lgb[c] = T_lgb[c].astype(\"category\")\n",
    "\n",
    "y_arr = y.values\n",
    "\n",
    "# 2) pick sensible tree counts (fallbacks if not defined earlier)\n",
    "cat_n  = 270  # median from your good CV earlier (approx 261–397 range)\n",
    "lgb_n  = int(globals().get(\"best_n_lgb\", 300))\n",
    "\n",
    "seeds = [42, 202, 777]\n",
    "\n",
    "# 3) train several seeds and average probs\n",
    "proba_cat_all, proba_lgb_all = [], []\n",
    "\n",
    "for sd in seeds:\n",
    "    # CatBoost full fit\n",
    "    m_cb = CatBoostClassifier(\n",
    "        loss_function=\"Logloss\",\n",
    "        eval_metric=\"Accuracy\",\n",
    "        depth=8,\n",
    "        learning_rate=0.08,\n",
    "        n_estimators=cat_n,\n",
    "        l2_leaf_reg=3,\n",
    "        random_seed=sd,\n",
    "        verbose=False\n",
    "    )\n",
    "    m_cb.fit(X_cb, y_arr, cat_features=cat_idx)\n",
    "    proba_cat_all.append(m_cb.predict_proba(T_cb)[:,1])\n",
    "\n",
    "    # LightGBM full fit\n",
    "    m_lgb = lgb.LGBMClassifier(\n",
    "        objective=\"binary\",\n",
    "        learning_rate=0.06,\n",
    "        num_leaves=64,\n",
    "        feature_fraction=0.9,\n",
    "        bagging_fraction=0.9,\n",
    "        bagging_freq=1,\n",
    "        n_estimators=lgb_n,\n",
    "        random_state=sd\n",
    "    )\n",
    "    m_lgb.fit(X_lgb, y_arr)\n",
    "    proba_lgb_all.append(m_lgb.predict_proba(T_lgb)[:,1])\n",
    "\n",
    "proba_cat = np.mean(np.vstack(proba_cat_all), axis=0)\n",
    "proba_lgb = np.mean(np.vstack(proba_lgb_all), axis=0)\n",
    "\n",
    "# 4) 50/50 blend (your best LB so far)\n",
    "proba_blend = 0.5*proba_cat + 0.5*proba_lgb\n",
    "pred_bool = proba_blend >= 0.5\n",
    "\n",
    "sub_ens = pd.DataFrame({\"PassengerId\": test[\"PassengerId\"], \"Transported\": pred_bool})\n",
    "sub_ens.to_csv(\"submission_seed_ens_blend_3x.csv\", index=False)\n",
    "print(\"Saved: submission_seed_ens_blend_3x.csv\")\n",
    "sub_ens.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06ab18b2-f15c-4f39-820d-1d9bbadb2688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId  Transported\n",
       "0     0013_01         True\n",
       "1     0018_01        False\n",
       "2     0019_01         True\n",
       "3     0021_01         True\n",
       "4     0023_01         True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CatBoost-weighted blend (alpha = 0.60)\n",
    "import pandas as pd\n",
    "\n",
    "alpha = 0.60\n",
    "proba_blend_060 = alpha*proba_cat + (1-alpha)*proba_lgb\n",
    "pred_bool_060 = proba_blend_060 >= 0.5\n",
    "\n",
    "sub_060 = pd.DataFrame({\n",
    "    \"PassengerId\": test[\"PassengerId\"],\n",
    "    \"Transported\": pred_bool_060\n",
    "})\n",
    "sub_060.to_csv(\"submission_seed_ens_alpha_060.csv\", index=False)\n",
    "sub_060.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc5a20cb-9127-4592-bcc3-19fda09023a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0018_01</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0019_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0021_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0023_01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PassengerId  Transported\n",
       "0     0013_01         True\n",
       "1     0018_01        False\n",
       "2     0019_01         True\n",
       "3     0021_01         True\n",
       "4     0023_01         True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CatBoost-weighted blend (alpha = 0.62)\n",
    "import pandas as pd\n",
    "\n",
    "alpha = 0.62\n",
    "proba_blend_062 = alpha*proba_cat + (1-alpha)*proba_lgb\n",
    "pred_bool_062 = proba_blend_062 >= 0.5\n",
    "\n",
    "sub_062 = pd.DataFrame({\n",
    "    \"PassengerId\": test[\"PassengerId\"],\n",
    "    \"Transported\": pred_bool_062\n",
    "})\n",
    "sub_062.to_csv(\"submission_seed_ens_alpha_062.csv\", index=False)\n",
    "sub_062.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25fad35-6511-4228-9f82-4d83c6f0f3be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (stitanic)",
   "language": "python",
   "name": "stitanic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
